# ğŸ§  Thai Summarization (mT5 + ThaiSum Dataset)

This project implements **Thai text summarization** using **mT5**, trained and evaluated on the **ThaiSum** dataset.  
It explores three training strategies â€” **Full Fine-tuning**, **Parameter-efficient LoRA**, and **Keyword-based Fine-tuning** â€”  
and evaluates their performance using **ROUGE** and **BERTScore**.

---

## ğŸ“‚ Project Structure

```
thai-summarization/
â”‚
â”œâ”€â”€ data/                        # Evaluation results and logs
â”œâ”€â”€ model/                       # Trained model checkpoints
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ preprocess.py            # Dataset loading & preprocessing
â”‚   â”œâ”€â”€ train.py                 # Full fine-tuning & LoRA
â”‚   â”œâ”€â”€ train_keyword.py         # Keyword-based fine-tuning
â”‚   â”œâ”€â”€ evaluate_model.py        # Evaluation (ROUGE, BERTScore)
â”‚   â””â”€â”€ summarize.py             # Generate summaries
â””â”€â”€ README.md                    # Project documentation
```

---

## âš™ï¸ Environment Setup

### ğŸªŸ Windows
```bash
python -m venv .venv
.venv\Scripts\activate
pip install -r requirements.txt
```

### ğŸ macOS / ğŸ§ Linux
```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### ğŸ”¥ Install PyTorch

> âš ï¸ Install **PyTorch after** installing requirements.txt

#### ğŸ–¥ï¸ CUDA GPU
```bash
pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu126
```

#### ğŸ Apple Silicon (M-series)
```bash
pip3 install torch torchvision
```

---

## ğŸš€ Training Methods

### ğŸ§© 1. Full Fine-tuning

Fine-tune the entire **mT5** model on ThaiSum.

```bash
python src/train.py --epochs 2 --learning_rate 5e-5 --batch_size 8 --size 1.0
```

### âš™ï¸ 2. LoRA Fine-tuning (Parameter-efficient)

Fine-tune only small adapter layers (~0.4% of parameters).

```bash
python src/train.py --lora --lora_r 8 --lora_alpha 16 --lora_dropout 0.05 \
    --epochs 2 --learning_rate 1e-3 --batch_size 8
```

### ğŸ”‘ 3. Keyword-based Fine-tuning (Ours)

Train mT5 with **keyword-augmented input**.
The model receives both extracted keywords and article body:

```
Keywords: k1, k2, k3 | Article: <text>
```

```bash
python src/train_keyword.py --epochs 2 --learning_rate 5e-5 --keyword_mode_train overlap
```

---

## ğŸ“Š Evaluation

Evaluate any trained model or pre-trained mT5 using **ROUGE** and **BERTScore**.

### Example

```bash
# Fine-tuned
python src/evaluate_model.py --model ./model/FineTuned-100 --split test

# LoRA model
python src/evaluate_model.py --model ./model/LoRA-100 --split test

# Keyword-based (with keyword extraction during eval)
python src/evaluate_model.py --model ./model/Keyword-100 --split test --use_keywords
```

### Output

```
./data/{name}/
â”œâ”€â”€ predictions_test.txt      # Model-generated summaries
â”œâ”€â”€ references_test.txt       # Gold summaries
â”œâ”€â”€ inputs_test.txt           # Input articles (with or w/o keywords)
â””â”€â”€ score/
    â”œâ”€â”€ metrics.json          # Detailed metrics
    â””â”€â”€ metrics_readable.txt  # Human-readable results
```

---

## ğŸ§  Evaluation Metrics

| Metric              | Description                                                                |
| :------------------ | :------------------------------------------------------------------------- |
| **ROUGE-1 / 2 / L** | Measures lexical overlap between generated and reference summaries         |
| **BERTScore (F1)**  | Measures semantic similarity between summaries using contextual embeddings |

---

## ğŸ§ª Experimental Results

| Model                        |  ROUGE-1  |  ROUGE-2  |  ROUGE-L  | BERTScore (F1) | Train Time |
| :--------------------------- | :-------: | :-------: | :-------: | :------------: | :--------: |
| **Zero-shot mT5**            |    2.73   |    0.73   |    2.71   |      78.28     |      â€”     |
| **Fine-tuned mT5**           |   53.44   |   34.02   |   53.38   |      95.36     |   ~12 hrs  |
| **LoRA Fine-tuned mT5**      | **53.94** | **34.60** | **53.86** |    **95.47**   |   ~7 hrs   |
| **Keyword-based mT5 (Ours)** |   42.60   |   25.33   |   42.45   |      93.29     |   ~11 hrs  |

ğŸŸ© **LoRA achieved comparable performance to full fine-tuning** while training <1% parameters.
ğŸŸ¦ **Keyword-based model** produced summaries that are semantically correct (high BERTScore)
but stylistically different (lower ROUGE).

---

## ğŸ’¬ Custom Summarization

```bash
python src/summarize.py --model ./model/FineTuned-100 \
  --text "à¸à¸£à¸¸à¸‡à¹€à¸—à¸à¸¡à¸«à¸²à¸™à¸„à¸£ - à¸§à¸±à¸™à¸™à¸µà¹‰à¸à¸£à¸¡à¸­à¸¸à¸•à¸¸à¸™à¸´à¸¢à¸¡à¸§à¸´à¸—à¸¢à¸²à¸à¸¢à¸²à¸à¸£à¸“à¹Œà¸­à¸²à¸à¸²à¸¨à¸§à¹ˆà¸²à¸ˆà¸°à¸¡à¸µà¸à¸™à¸Ÿà¹‰à¸²à¸„à¸°à¸™à¸­à¸‡..."
```

---

## ğŸ“– References

* **Dataset:** [ThaiSum (PyThaiNLP)](https://huggingface.co/datasets/pythainlp/thaisum)
* **Base Model:** [google/mt5-small](https://huggingface.co/google/mt5-small)
* **LoRA Technique:** Hu et al., *LoRA: Low-Rank Adaptation of Large Language Models*, ICLR 2022
* **Keyword-based Approach:** Adapted from *Automatic Thai Text Summarization Using Keyword-Based Abstractive Method (2022)*
* **Evaluation:** [Hugging Face Evaluate â€“ ROUGE, BERTScore](https://huggingface.co/docs/evaluate)

---

<div align="center">

**Author:** Nontapat Chucharnchai
**Advisor:** â€”
**Environment:** Python 3.10+, PyTorch, Hugging Face Transformers
**License:** Research / Academic Use Only

</div>
